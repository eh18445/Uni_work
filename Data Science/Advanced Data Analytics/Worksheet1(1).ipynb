{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1 worksheet\n",
    "\n",
    "In this worksheet we will explore some of the basic concepts of statistical pattern analysis and linear data projection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by generating 3000 data values from a one-dimensional Gaussian with mean 2 and variance 5. Note how the seed of the random number generator has been fixed to enable us to reproduce results reliably. This is crucial for debugging and auditing applications of data science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import Generator, PCG64\n",
    "mean = 2\n",
    "sigma = np.sqrt(5)\n",
    "rng = Generator(PCG64(12345))\n",
    "vals = mean + sigma*rng.standard_normal(3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a histogram of this data with 30 bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute the maximum likelihood estimates of the mean and standard deviation of the data. Print the values and make a note of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is one result for maximum likelihood estimation based on a single sample from the distribution. Now we will do this 100 times with a smaller sample (of size 10) and compare the average estimate of the mean (over the 100 iterations) with its true value and the average estimate of the variance (over the 100 iterations) with its true value. (Continue with the random number generator in its current state (i.e. do not reset it)). Print out these values and make a note of them for the quiz later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis (PCA) for data projection\n",
    "\n",
    "In this section we will explore the theory and practice of PCA for data projection.\n",
    "\n",
    "We start by reading in the oil flow dataset mentioned in the lectures. The ID field is simply the index of the row in the dataset (starting from 1). The variables have the imaginative names v1, v2, etc. While the final column is the class label, which will be treated separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>v10</th>\n",
       "      <th>v11</th>\n",
       "      <th>v12</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.3315</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.6802</td>\n",
       "      <td>0.1434</td>\n",
       "      <td>0.6825</td>\n",
       "      <td>0.2720</td>\n",
       "      <td>0.6223</td>\n",
       "      <td>0.2092</td>\n",
       "      <td>0.7961</td>\n",
       "      <td>0.1530</td>\n",
       "      <td>0.5856</td>\n",
       "      <td>0.2573</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5184</td>\n",
       "      <td>0.2283</td>\n",
       "      <td>0.5300</td>\n",
       "      <td>0.6884</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.6171</td>\n",
       "      <td>0.6136</td>\n",
       "      <td>0.5928</td>\n",
       "      <td>0.7678</td>\n",
       "      <td>0.6130</td>\n",
       "      <td>0.6705</td>\n",
       "      <td>0.5202</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0760</td>\n",
       "      <td>0.5010</td>\n",
       "      <td>0.1870</td>\n",
       "      <td>0.7011</td>\n",
       "      <td>0.1728</td>\n",
       "      <td>0.8475</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>0.6536</td>\n",
       "      <td>0.1616</td>\n",
       "      <td>0.8732</td>\n",
       "      <td>0.1603</td>\n",
       "      <td>0.7331</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.3334</td>\n",
       "      <td>0.5468</td>\n",
       "      <td>0.6072</td>\n",
       "      <td>0.7549</td>\n",
       "      <td>0.6294</td>\n",
       "      <td>0.9322</td>\n",
       "      <td>0.5850</td>\n",
       "      <td>0.7859</td>\n",
       "      <td>0.6324</td>\n",
       "      <td>0.9568</td>\n",
       "      <td>0.6026</td>\n",
       "      <td>0.7616</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.2234</td>\n",
       "      <td>0.2677</td>\n",
       "      <td>0.3477</td>\n",
       "      <td>0.2734</td>\n",
       "      <td>0.4324</td>\n",
       "      <td>0.1222</td>\n",
       "      <td>0.5213</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>0.4926</td>\n",
       "      <td>0.2044</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        v1      v2      v3      v4      v5      v6      v7      v8      v9  \\\n",
       "ID                                                                           \n",
       "1   0.3315  0.2156  0.6802  0.1434  0.6825  0.2720  0.6223  0.2092  0.7961   \n",
       "2   0.5184  0.2283  0.5300  0.6884  0.7456  0.6171  0.6136  0.5928  0.7678   \n",
       "3   0.0760  0.5010  0.1870  0.7011  0.1728  0.8475  0.2300  0.6536  0.1616   \n",
       "4   0.3334  0.5468  0.6072  0.7549  0.6294  0.9322  0.5850  0.7859  0.6324   \n",
       "5   0.1703  0.2234  0.2677  0.3477  0.2734  0.4324  0.1222  0.5213  0.2333   \n",
       "\n",
       "       v10     v11     v12  Label  \n",
       "ID                                 \n",
       "1   0.1530  0.5856  0.2573      1  \n",
       "2   0.6130  0.6705  0.5202      1  \n",
       "3   0.8732  0.1603  0.7331      1  \n",
       "4   0.9568  0.6026  0.7616      1  \n",
       "5   0.4926  0.2044  0.4215      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas \n",
    "\n",
    "df = pandas.read_csv('oil.csv', index_col='ID')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, compute the covariance matrix of the data (just v1 to v12) and then carry out an eigendecomposition: check the `numpy` definitions of the appropriate functions. Store the eigenvalues in a variable `eval` and the eigenvectors in a variable `evec`. Start by using the `eig` function. \n",
    "\n",
    "Note that in the `eig` function each row of the matrix parameter represents a variable, and each column a single observation of all those variables. This is the opposite to the convention in Matlab and in Chris Bishop's book. Either apply a transpose operator or set the `rowvar` parameter to `false`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we list and plot the eigenvalues. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment code when previous section is completed\n",
    "#print (eval)\n",
    "#plt.figure()\n",
    "#plt.subplot(211)\n",
    "#plt.plot( eval, 'ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can see the effect of different algorithms for calculating the eigenvalues and eigenvectors. The `eigh` function is specialised for working with symmetric matrices: it is faster and more accurate than `eig` in this case. Use it to compute eigenvalues and eigenvectors for this task (again with the same variable names). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO - then uncomment plotting code\n",
    "\n",
    "#plt.subplot(212)\n",
    "#plt.plot( eval, 'ok')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next task is to sort the eigenvalues in descending order (If we were using the vectors to project the data, we would have to rearrange the eigenvectors correspondingly). \n",
    "\n",
    "Then you should write code to compute the cumulative sums of the resulting vector and express the values as a fraction of the total of the eigenvalues (compare with the lecture notes). Plot the cumulative sum. I have provided code to draw a threshold at 0.95."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the eigenvalues - should also reorder the eigenvectors if applying them\n",
    "# Uncomment code when TODO section is complete\n",
    "#sorted_eval = np.sort(eval)\n",
    "#eval = sorted_eval[::-1]  # reverse the order so that it is decreasing\n",
    "#print(\"Sorted eigenvalues \" + str(eval))\n",
    "\n",
    "# TODO Compute cumulative sum\n",
    "\n",
    "\n",
    "# Plot cumulative sum of eigenvalues with a threshold at 0.95\n",
    "# Uncomment code when TODO section is complete\n",
    "#plt.figure(3)\n",
    "#plt.plot(cumuleval, 'ok')\n",
    "#xvals = range(ncols-1)\n",
    "#plt.plot(xvals, 0.95*np.ones(np.shape(eval)), 'r-')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now write code to apply PCA (look up the function definition) with 2 principal components and then project the data onto this space using the `transform` function (which automatically subtracts off the mean of each variable). Call the resulting variable `projX`. Generate a scatter plot of the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-f407dbb3da28>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecomposition\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m# This should equal the sum of the first two values in the cumulative proportion plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Explained variance ratio '\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# Now apply PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X)\n",
    "# This should equal the sum of the first two values in the cumulative proportion plot\n",
    "print('Explained variance ratio '+ str(pca.explained_variance_ratio_))\n",
    "\n",
    "# Project data onto first two principal components\n",
    "projX = pca.transform(X)\n",
    "plt.figure(4)\n",
    "plt.plot(projX[:,0], projX[:,1], 'k.')\n",
    "plt.title('Projected data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph is interesting - it shows the structure of the data quite well in terms of clusters and outliers. But we also have extra information that we can plot: namely the class labels. The following piece of code uses the label to colour each mark: red circle, green cross, and blue square for labels 1, 2, and 3 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plot the data with a different mark for each label\n",
    "marks = ('ro', 'g+', 'bs')\n",
    "plt.figure(6)\n",
    "for n in range(1, 4, 1) :\n",
    "    projClass = projX[np.equal(label, n*np.ones(label.shape))]\n",
    "    plt.plot(projClass[:,0], projClass[:,1], marks[n-1])\n",
    "\n",
    "plt.title('Projected data showing label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA: dimensionality reduction\n",
    "\n",
    "In this section, we will explore the use of PCA for dimensionality reduction and reconstruction. We will work with the digit dataset provided by `sklearn`, though it does have drawbacks given the small $8 \\times 8$ size of the images.\n",
    "\n",
    "Here we load the data and then display the first image, which is a zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    " \n",
    "plt.gray() \n",
    "plt.matshow(digits.images[0]) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you haven't seen this dataset before, it is useful to know what the objects are stored with it. Note that `data` is a matrix with one digit per row and 64 columns (representing the 64 pixel values) while `images` is a list of images each of which is an $8\\times 8$ matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(digits.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, compute the top 30 principal components of the `data` and then show the first component as an image. N.B. You will need to reshape the component as an $8\\times 8$ matrix before plotting it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next you should write code to project the first few rows (say $10$) of the data to the PCA subspace (using `transform`) and then _reconstruct_ the first digit in the original space using the `inverse_transform` function. Display the reconstructed digit as an image as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By printing the first few values of the targets, we see that the digits are encoded by the corresponding number 0-9. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(digits.target[0:20])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use this fact to create a subset of the data consisting only of the digit 3. Write code to do this (you may find it useful to look at the indexing trick in the definition of `projClass` above) and then compute and show the first principal component. We can call it an _eigendigit_. How does this compare with the principal component computing on the entire dataset? Why do you think there is a difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The eigendigit for the entire dataset shows all the variations in all the digits so is not recognisably related to any specific digit. The low resolution makes interpretation difficult, but there is some indication that the eigendigit for 3 does have some structure in it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fisher linear discriminant\n",
    "In this final exercise, we will explore the Fisher linear discriminant implementation and compare the results with PCA. We will work with the oil data again and extract the last column to a vector `label`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work with oil data again\n",
    "\n",
    "df = pandas.read_csv('oil.csv', index_col='ID')\n",
    "df.head()\n",
    "\n",
    "data = df.to_numpy()\n",
    "ncols = data.shape[1]\n",
    "\n",
    "X = data[:,0:ncols-1]\n",
    "label = data[:,ncols-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now apply `LinearDiscriminantAnalysis` from `sklearn` and project the data to a variable `projX`. The rest of the code in the next block plots the data in the same way as for PCA above. Write down two differences between the PCA and Fisher discriminant projections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "\n",
    "# Now plot the data with a different mark for each label\n",
    "marks = ('ro', 'g+', 'bs')\n",
    "plt.figure()\n",
    "for n in range(1, 4, 1) :\n",
    "    projClass = projX[np.equal(label, n*np.ones(label.shape))]\n",
    "    plt.plot(projClass[:,0], projClass[:,1], marks[n-1])\n",
    "\n",
    "plt.title('Projected data showing label')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
