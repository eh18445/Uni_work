{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Performance\n",
    "\n",
    "In this section we will look at ways of measuring the \"efficiency\" of our code. In this context, efficiency refers to the numer of cpu operations that are required to complete a calculation. The fewer operations required to complete a calculation, the faster it will run, and the more efficient the code.\n",
    "\n",
    "\n",
    "## Interpretation vs Compilation\n",
    "\n",
    "To start with, it's useful to understand a key difference between different types of computer language : _compiled_ vs _interpreted_.\n",
    "\n",
    "With _compiled_ languages like C, C++, Fortran, going from code (text) to a program is a two step process. First, a dedicated _compiler_ program parses (reads) the high-level code and converts it into instructions that can be understood by the cpu. The compiler outputs an executable binary file, which you then have to run in a second step. Compilation can potentially take a long time, but this allows the executable to be highly optimised and efficient. On the other hand, when the executable is highly optimised, it bears little resemblance to the original code, and debugging can become more difficult.\n",
    "\n",
    "With _interpreted_ languages, like Python, there is no separate compiler, and no executable.  The code you write is parsed, compiled, and executed, at the time you run the program by an _interpreter_. The compilation step is omitted, simplifying the process. However, the interpreters ability to optimise the code is reduced and in general, interpreted languages are not nearly as fast as compiled languages.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `time` library\n",
    "\n",
    "We can investigate code efficiency by measuring how long a function takes to run. All computers generally have an internal clock, which can provide the date and time to some precision, depending on the machine and operating system. Most computers will provide the time in seconds since `January 1, 1970, 00:00:00` (aka \"the epoch\"). \n",
    "\n",
    "Python's `time` library provides a range of functions. `time.time()` will return the time in second since the epoch, however its precision varies from one platform to another. `time.perf_counter()` is more useful here, since it will provide the best precision available on the platform, however it can only be used for measuring relative time (ie. the difference between repeated calls to `time.perf_counter()`.  We can use this to measure the time elapsed during execution of a function, as in the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n"
     ]
    }
   ],
   "source": [
    "# first define the function we want to time\n",
    "def simple_sum(arr_in):\n",
    "    result = 0\n",
    "    for i in range(len(arr_in)):\n",
    "        result = result + arr_in[i]\n",
    "    return result\n",
    "\n",
    "a = [1., 2., 3.]\n",
    "print(simple_sum(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.660000028408831e-05\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.perf_counter()\n",
    "simple_sum(a)\n",
    "#time.sleep(5)\n",
    "end = time.perf_counter()\n",
    "\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try running the cell above several times. You should see some variation. If you are able to do this while your computer is also doing something computationally intensive, you might see some really big variation. If you don't see much variation in time, uncomment the `time.sleep` line above - you should see that sending the process to sleep between the time measurements affects the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Execution Time\n",
    "\n",
    "A key issue to note here is that modern cpus are designed to run multiple programs simultaneously, using 'multi-threading' techniques to switch between processes and make efficient use of the cpu. Our function above might be held in a queue before it can run, or it might be interrupted in the middle of its operation. Using the absolute time (known as the \"wall clock\" time) can be therefore give misleading results.  Really we want an estimate of the \"cpu time\" (the time spend by the cpu executing this function) rather than the \"wall clock time\" (the absolute time difference between the start and end of the execution).\n",
    "\n",
    "An improvement on `time.perf_counter()` is therefore to use `time.process_time()`.  This will return the time elapsed while the cpu is executing a single process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "simple_sum(a)\n",
    "#time.sleep(5)\n",
    "end = time.process_time()\n",
    "\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you should see less variation.  If you try uncommenting the sleep line, you should see the process will go to sleep for 5 seconds, but since the cpu does not spend this time executing the process, it will not impact the measured time interval.\n",
    "\n",
    "The final point to note here is that the time values measured here are very small. In general, fast functions will execute in time that is comparable to the resolution of the time measurement.  To avoid this, it is best to make sure the time interval you measure is around 1s. You can achieve this by running the function many times, and dividing the measured interval by the number of function calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.375e-07\n"
     ]
    }
   ],
   "source": [
    "n=int(1e5)\n",
    "start = time.process_time()\n",
    "for i in range(n):\n",
    "    simple_sum(a)\n",
    "end = time.process_time()\n",
    "\n",
    "print((end-start)/n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worth exploring what happens as you reduced the number of calls to `simple_sum()` in the cell above. You should see the mean value starts to increase, as the total time gets close to the resolution of `time.process_time()`.\n",
    "\n",
    "Note that you will still see variation in estimated time when running the cell above repeatedly. This results from imperfections in the ability of `time.process_time()` to measure the true time spent by the cpu in the process (which is non-trivial). We can account for this by repeating the measurement several times. Note that when repeating this measurement we want to take the _smallest_ value! Unlikel typical measurements, here we know that the variation results from processes that are external to the one we are trying to measure, and all variation increases the measured value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.09375e-06\n"
     ]
    }
   ],
   "source": [
    "times = []\n",
    "\n",
    "for i in range(10):\n",
    "    start = time.process_time()\n",
    "    for i in range(n):\n",
    "        simple_sum(a)\n",
    "    end = time.process_time()\n",
    "    times.append((end-start)/n)\n",
    "\n",
    "print(min(times))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On my laptop, I obtain values for the execution time of `simple_sum()` that are all around 1.3$\\mu$s. Note that this will vary from one machine to another, depending on its specification.\n",
    "\n",
    "In summary, to obtain accurate estimates of function execution time :\n",
    "1. measure cpu time, not wall clock time\n",
    "2. time the execution of many calls to the function, with total time > 0.1s\n",
    "3. repeat the above several times and take the smallest value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `timeit` library\n",
    "\n",
    "Fortunately, the `timeit` library includes pre-defined functions explicitly for measuring function execution time. Full details are available at : https://docs.python.org/3/library/timeit.html\n",
    "\n",
    "`timeit.timeit` will measure a specified number of calls to a function, and return the total measure time. `timeit.repeat` will do the same, but repeat this a specified number of times and return a list. In both cases, the function to be timed must be passed as a 'callable' (a function without brackets, and hence without arguments), which we can achieve a lambda function (see $\\S$2 below).  Also note the timer function can be specified - by default it is time.perf_counter().\n",
    "\n",
    "The example below implements does the same thing as the previous code cell, using `timeit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.25e-06\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "times = timeit.repeat(lambda: simple_sum(a), number=n, repeat=10, timer=time.process_time )\n",
    "print(min(times)/n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example - Vectorisation\n",
    "\n",
    "Vectorisation was introduced in the 2nd year Python tutorial ($\\S$5.1). Essentally, vectorisation allows us to perform an operation on every element of a numpy array. Numpy provides a wide range of functions that support vectorisation.\n",
    "\n",
    "In this section, we'll look at the performance increase that vectorisation can offer. As an example, we'll look at finding the square of each element in a large numpy array. First, we'll implement this using a for loop, and time it with the `timeit` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4556897199999952\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "old = np.arange(1000)\n",
    "new = np.empty(1000)\n",
    "\n",
    "def forloop():\n",
    "    for i in range(1000):\n",
    "        new[i] = old[i]**2\n",
    "    return new\n",
    "\n",
    "from timeit import Timer\n",
    "\n",
    "print(min(Timer(forloop).repeat(number=1000, repeat=10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now using numpy vectorised routines instead.  Note that we wrap the numpy call up in a function to make the comparison as fair as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0014118909999893958\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def nploop():\n",
    "    return old**2\n",
    "\n",
    "print(min(Timer(nploop).repeat(number=1000, repeat=10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the performance increase is significant !  This is achieved because, like many Python libraries, it uses _compiled_ code (usually C, sometimes Fortran) behind the scenes.  By using a vectorised operated, the 'for loop' is implemented in that compiled code, so Python only has to interpret a handful of lines.  In the first example, Python will interpret every iteration of the for loop individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
